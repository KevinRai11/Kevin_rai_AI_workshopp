{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNncPGurM9O/Gk5VBU07MxS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Build a Custom Decision Tree\n"],"metadata":{"id":"76S8NRnaeHwA"}},{"cell_type":"code","source":["import numpy as np\n","\n","class CustomDecisionTree:\n","    def __init__(self, max_depth=None):\n","        \"\"\"\n","        Initializes the decision tree with the specified maximum depth.\n","\n","        Parameters:\n","        max_depth (int, optional): The maximum depth of the tree. If None, the tree is expanded until all leaves are pure or contain fewer than the minimum samples required to split.\n","        \"\"\"\n","        self.max_depth = max_depth\n","        self.tree = None\n","\n","    def fit(self, X, y):\n","        \"\"\"\n","        Trains the decision tree model using the provided training data.\n","\n","        Parameters:\n","        X (array-like): Feature matrix (n_samples, n_features) for training the model.\n","        y (array-like): Target labels (n_samples,) for training the model.\n","        \"\"\"\n","        self.tree = self._build_tree(X, y)\n","\n","    def _build_tree(self, X, y, depth=0):\n","        \"\"\"\n","        Recursively builds the decision tree by splitting the data based on the best feature and threshold.\n","\n","        Parameters:\n","        X (array-like): Feature matrix (n_samples, n_features) for splitting.\n","        y (array-like): Target labels (n_samples,) for splitting.\n","        depth (int, optional): Current depth of the tree during recursion.\n","\n","        Returns:\n","        dict: A dictionary representing the structure of the tree, containing the best feature index, threshold, and recursive tree nodes.\n","        \"\"\"\n","        num_samples, num_features = X.shape\n","        unique_classes = np.unique(y)\n","\n","        # Stopping conditions: pure node or reached max depth\n","        if len(unique_classes) == 1:\n","            return {'class': unique_classes[0]}\n","        if num_samples == 0 or (self.max_depth and depth >= self.max_depth):\n","            return {'class': np.bincount(y).argmax()}\n","\n","        # Find the best split based on Information Gain (using Entropy)\n","        best_info_gain = -float('inf')\n","        best_split = None\n","        for feature_idx in range(num_features):\n","            thresholds = np.unique(X[:, feature_idx])\n","            for threshold in thresholds:\n","                left_mask = X[:, feature_idx] <= threshold\n","                right_mask = ~left_mask\n","                left_y = y[left_mask]\n","                right_y = y[right_mask]\n","\n","                info_gain = self._information_gain(y, left_y, right_y)\n","\n","                if info_gain > best_info_gain:\n","                    best_info_gain = info_gain\n","                    best_split = {\n","                        'feature_idx': feature_idx,\n","                        'threshold': threshold,\n","                        'left_y': left_y,\n","                        'right_y': right_y,\n","                    }\n","\n","        if best_split is None:\n","            return {'class': np.bincount(y).argmax()}\n","\n","        # Recursively build the left and right subtrees\n","        left_tree = self._build_tree(X[best_split['left_y']], best_split['left_y'], depth + 1)\n","        right_tree = self._build_tree(X[best_split['right_y']], best_split['right_y'], depth + 1)\n","\n","        return {'feature_idx': best_split['feature_idx'], 'threshold': best_split['threshold'],\n","                'left_tree': left_tree, 'right_tree': right_tree}\n","\n","    def _information_gain(self, parent, left, right):\n","        \"\"\"\n","        Computes the Information Gain between the parent node and the left/right child nodes.\n","\n","        Parameters:\n","        parent (array-like): The labels of the parent node.\n","        left (array-like): The labels of the left child node.\n","        right (array-like): The labels of the right child node.\n","\n","        Returns:\n","        float: The Information Gain of the split.\n","        \"\"\"\n","        parent_entropy = self._entropy(parent)\n","        left_entropy = self._entropy(left)\n","        right_entropy = self._entropy(right)\n","\n","        # Information Gain = Entropy(parent) - (weighted average of left and right entropies)\n","        weighted_avg_entropy = (len(left) / len(parent)) * left_entropy + (len(right) / len(parent)) * right_entropy\n","        return parent_entropy - weighted_avg_entropy\n","\n","    def _entropy(self, y):\n","        \"\"\"\n","        Computes the entropy of a set of labels.\n","\n","        Parameters:\n","        y (array-like): The labels for which entropy is calculated.\n","\n","        Returns:\n","        float: The entropy of the labels.\n","        \"\"\"\n","        # Calculate the probability of each class\n","        class_probs = np.bincount(y) / len(y)\n","        # Compute the entropy using the formula: -sum(p * log2(p))\n","        return -np.sum(class_probs * np.log2(class_probs + 1e-9))  # Added small epsilon to avoid log(0)\n","\n","    def predict(self, X):\n","        \"\"\"\n","        Predicts the target labels for the given test data based on the trained decision tree.\n","\n","        Parameters:\n","        X (array-like): Feature matrix (n_samples, n_features) for prediction.\n","\n","        Returns:\n","        list: A list of predicted target labels (n_samples,).\n","        \"\"\"\n","        return [self._predict_single(x, self.tree) for x in X]\n","\n","    def _predict_single(self, x, tree):\n","        \"\"\"\n","        Recursively predicts the target label for a single sample by traversing the tree.\n","\n","        Parameters:\n","        x (array-like): A single feature vector for prediction.\n","        tree (dict): The current subtree or node to evaluate.\n","\n","        Returns:\n","        int: The predicted class label for the sample.\n","        \"\"\"\n","        if 'class' in tree:\n","            return tree['class']\n","\n","        feature_val = x[tree['feature_idx']]\n","        if feature_val <= tree['threshold']:\n","            return self._predict_single(x, tree['left_tree'])\n","        else:\n","            return self._predict_single(x, tree['right_tree'])\n"],"metadata":{"id":"-wPtNGHRerWL","executionInfo":{"status":"ok","timestamp":1736751891989,"user_tz":-345,"elapsed":874,"user":{"displayName":"Surajkiran Shrestha","userId":"01832979019123023073"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Necessary Imports"],"metadata":{"id":"qMV5VfL5e8vo"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"GsaW1qFufBmo","executionInfo":{"status":"ok","timestamp":1736751982716,"user_tz":-345,"elapsed":592,"user":{"displayName":"Surajkiran Shrestha","userId":"01832979019123023073"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Load and Split the Iris Dataset"],"metadata":{"id":"9G7UmH3MfC4-"}},{"cell_type":"code","source":["# Load the Iris dataset\n","data = load_iris()\n","X = data.data\n","y = data.target\n","\n","# Split into training and test sets (80% training, 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"],"metadata":{"id":"NmdK_tSAfGZo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train and Evaluate the Custom Decision Tree"],"metadata":{"id":"1UpWWT5xfJL4"}},{"cell_type":"code","source":["# Train the custom decision tree\n","custom_tree = CustomDecisionTree(max_depth=3)\n","custom_tree.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred_custom = custom_tree.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy_custom = accuracy_score(y_test, y_pred_custom)\n","print(f\"Custom Decision Tree Accuracy: {accuracy_custom:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wA1SAPJlfM6i","executionInfo":{"status":"ok","timestamp":1736752029184,"user_tz":-345,"elapsed":569,"user":{"displayName":"Surajkiran Shrestha","userId":"01832979019123023073"}},"outputId":"4b6723e1-e958-473d-9e4c-18f336d7fb94"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Custom Decision Tree Accuracy: 0.7222\n"]}]},{"cell_type":"markdown","source":["## Train and Evaluate the scikit-learn Decision Tree"],"metadata":{"id":"AGE7GslVfOie"}},{"cell_type":"code","source":["# Train the Scikit-learn decision tree\n","sklearn_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n","sklearn_tree.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred_sklearn = sklearn_tree.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n","print(f\"Scikit-learn Decision Tree Accuracy: {accuracy_sklearn:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rz7z29_hfSBy","executionInfo":{"status":"ok","timestamp":1736752053210,"user_tz":-345,"elapsed":566,"user":{"displayName":"Surajkiran Shrestha","userId":"01832979019123023073"}},"outputId":"093f0883-cea3-449c-ebd2-44e57de8d6d2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Scikit-learn Decision Tree Accuracy: 0.9444\n"]}]},{"cell_type":"markdown","source":["## Result Comparision"],"metadata":{"id":"VeCP5oiHfWEp"}},{"cell_type":"code","source":["print(f\"Accuracy Comparison:\")\n","print(f\"Custom Decision Tree: {accuracy_custom:.4f}\")\n","print(f\"Scikit-learn Decision Tree: {accuracy_sklearn:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OeHGGsIffXRX","executionInfo":{"status":"ok","timestamp":1736752075659,"user_tz":-345,"elapsed":556,"user":{"displayName":"Surajkiran Shrestha","userId":"01832979019123023073"}},"outputId":"e7b92dbd-7731-42ae-83f7-c272c19dadb0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy Comparison:\n","Custom Decision Tree: 0.7222\n","Scikit-learn Decision Tree: 0.9444\n"]}]},{"cell_type":"markdown","source":["2. Train a Decision Tree Classifier:"],"metadata":{"id":"iYa06adAfayY"}},{"cell_type":"code","source":["from sklearn.datasets import load_wine\n","from sklearn.model_selection import train_test_split\n","\n","# Load the wine dataset\n","data = load_wine()\n","X = data.data\n","y = data.target\n","\n","# Split into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"],"metadata":{"id":"w96h7SJRfbrp","executionInfo":{"status":"ok","timestamp":1736752092215,"user_tz":-345,"elapsed":564,"user":{"displayName":"Surajkiran Shrestha","userId":"01832979019123023073"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["3. Train a Random Forest Classifier:"],"metadata":{"id":"H4Z-6_SUfeYy"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import f1_score\n","\n","# Initialize and train the Decision Tree\n","dt_model = DecisionTreeClassifier(random_state=42)\n","dt_model.fit(X_train, y_train)\n","\n","# Predict and calculate the F1 score\n","y_pred_dt = dt_model.predict(X_test)\n","f1_dt = f1_score(y_test, y_pred_dt, average='weighted')  # 'weighted' accounts for class imbalance\n","print(f\"Decision Tree F1 Score: {f1_dt}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H9rBJv5Dfgjd","executionInfo":{"status":"ok","timestamp":1736752118217,"user_tz":-345,"elapsed":864,"user":{"displayName":"Surajkiran Shrestha","userId":"01832979019123023073"}},"outputId":"386d0a9b-7b6e-499f-9068-67de03605616"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Decision Tree F1 Score: 0.9439974457215836\n"]}]},{"cell_type":"markdown","source":["4. Compare the F1 Scores"],"metadata":{"id":"JEdgH7i6fkbB"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","# Initialize and train the Random Forest\n","rf_model = RandomForestClassifier(random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","# Predict and calculate the F1 score\n","y_pred_rf = rf_model.predict(X_test)\n","f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n","print(f\"Random Forest F1 Score: {f1_rf}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khmzHexGfmE3","executionInfo":{"status":"ok","timestamp":1736752136257,"user_tz":-345,"elapsed":1249,"user":{"displayName":"Surajkiran Shrestha","userId":"01832979019123023073"}},"outputId":"6ea8f0bb-6fa0-49a8-dfbe-3480dc65de5b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest F1 Score: 1.0\n"]}]},{"cell_type":"markdown","source":["2. Hyperparameter Tuning using GridSearchCV8"],"metadata":{"id":"PGMwaH0nfpMk"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {\n","    'n_estimators': [50, 100, 200],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10]\n","}\n","\n"],"metadata":{"id":"jdD38k-7fqOs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.Run GridSearchCV"],"metadata":{"id":"aV_ujuzHfuK4"}},{"cell_type":"code","source":["grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n","                           param_grid=param_grid,\n","                           cv=5,  # 5-fold cross-validation\n","                           n_jobs=-1,  # Use all available CPUs\n","                           scoring='f1_weighted')\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best parameters and best score\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best F1 Score:\", grid_search.best_score_)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NMbnkt5jfu4M","executionInfo":{"status":"ok","timestamp":1736752222485,"user_tz":-345,"elapsed":51689,"user":{"displayName":"Surajkiran Shrestha","userId":"01832979019123023073"}},"outputId":"7eeb6887-4da7-4dbe-fabc-023d7d1d01c1"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n","Best F1 Score: 0.9782952128219708\n"]}]},{"cell_type":"markdown","source":["3. . Regression Models (Decision Tree & Random Forest Regressors)"],"metadata":{"id":"k7uh-QVwfyde"}},{"cell_type":"markdown","source":["1.Load the Wine Dataset (Regression Version)"],"metadata":{"id":"-IaIK8czfzWH"}},{"cell_type":"code","source":["X = data.data\n","y = data.data[:, 0]  # First column as the target (can be any continuous feature)\n"],"metadata":{"id":"-juzFRgmf1zW","executionInfo":{"status":"ok","timestamp":1736752222485,"user_tz":-345,"elapsed":4,"user":{"displayName":"Surajkiran Shrestha","userId":"01832979019123023073"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["2.Train a Decision Tree Regressor:\n"],"metadata":{"id":"M8omxARmf5tH"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","# Initialize and train the Decision Tree Regressor\n","dt_regressor = DecisionTreeRegressor(random_state=42)\n","dt_regressor.fit(X_train, y_train)\n","\n","# Predict and evaluate the model\n","y_pred_dt_reg = dt_regressor.predict(X_test)\n","mse_dt = mean_squared_error(y_test, y_pred_dt_reg)\n","print(f\"Decision Tree Regressor MSE: {mse_dt}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_qDs0krf7R7","executionInfo":{"status":"ok","timestamp":1736752222485,"user_tz":-345,"elapsed":3,"user":{"displayName":"Surajkiran Shrestha","userId":"01832979019123023073"}},"outputId":"c4c86dd3-e745-4b5f-c536-65c2314f82b4"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Decision Tree Regressor MSE: 0.16666666666666666\n"]}]},{"cell_type":"markdown","source":["3.Train a Random Forest Regressor"],"metadata":{"id":"hSCCA01bf_rn"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","\n","# Initialize and train the Random Forest Regressor\n","rf_regressor = RandomForestRegressor(random_state=42)\n","rf_regressor.fit(X_train, y_train)\n","\n","# Predict and evaluate the model\n","y_pred_rf_reg = rf_regressor.predict(X_test)\n","mse_rf = mean_squared_error(y_test, y_pred_rf_reg)\n","print(f\"Random Forest Regressor MSE: {mse_rf}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DKN4PPggAlS","executionInfo":{"status":"ok","timestamp":1736752243664,"user_tz":-345,"elapsed":552,"user":{"displayName":"Surajkiran Shrestha","userId":"01832979019123023073"}},"outputId":"b943ca93-9231-4f0a-c1a8-84105bf39180"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Forest Regressor MSE: 0.06483333333333333\n"]}]},{"cell_type":"markdown","source":["4. Hyperparameter Tuning for Random Forest Regressor using RandomizedSearchCV\n"],"metadata":{"id":"mUgErwXIgIb3"}},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","import numpy as np\n","\n","param_dist = {\n","    'n_estimators': np.arange(50, 201, 50),\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10]\n","}\n","\n","randomized_search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42),\n","                                       param_distributions=param_dist,\n","                                       n_iter=10,  # Number of random combinations to try\n","                                       cv=5,\n","                                       n_jobs=-1,\n","                                       scoring='neg_mean_squared_error')  # MSE for regression\n","randomized_search.fit(X_train, y_train)\n","\n","# Get the best parameters and best score\n","print(\"Best parameters:\", randomized_search.best_params_)\n","print(\"Best score:\", randomized_search.best_score_)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"heB0UPGWgJQf","executionInfo":{"status":"ok","timestamp":1736752288819,"user_tz":-345,"elapsed":9122,"user":{"displayName":"Surajkiran Shrestha","userId":"01832979019123023073"}},"outputId":"204372d1-3c73-4aaa-87dc-ecd20c5e930e"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Best parameters: {'n_estimators': 150, 'min_samples_split': 2, 'max_depth': 10}\n","Best score: -0.045699781061850034\n"]}]}]}